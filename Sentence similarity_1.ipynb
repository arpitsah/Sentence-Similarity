{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "from nltk.tokenize import sent_tokenize as st\n",
    "import pandas as pd\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#spacy__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample_sentences = \"C:/Users/dinesh.panchal/Desktop/CA Folder/Rated_sentences.xlsx\" # Enter directory in place of '.'\n",
    "characteristics = \"BM_Chars.csv\"\n",
    "company = \"AR_sample.csv\"\n",
    "export_path = \"Results4.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defining stop words\n",
    "stop_words = ['a', '.', ',', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves',\n",
    "              'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him',\n",
    "              'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its',\n",
    "              'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "              'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n",
    "              'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been',\n",
    "              'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
    "              'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because',\n",
    "              'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about',\n",
    "              'against', 'between', 'into', 'through', 'during', 'before', 'after',\n",
    "              'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on',\n",
    "              'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "              'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each',\n",
    "              'few', 'more', 'most', 'other', 'some', 'such',\n",
    "              'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can',\n",
    "              'will', 'just', 'don','should', 'now','https',\"'s\",'...', \"whats'\",\n",
    "              \"rt\",\"whats\",\"n't\",\"de\",\"'m\",\"un\",\"en\",\"``\",\"dedic\",\"twittermoments\",\n",
    "              \"amp\",\"e\",\"y\",\"o\",\"ce\",\"retweet\",\"sur\",\"na\",\"el\",\"1\",\"2\",\"3\",\"4\",\n",
    "              \"5\",\"6\",\"7\",\"8\",\"9\",\"0\",\"ca\",\"nao\",\"se\",\"com\",\"los\",\"u\",\"des\",\"-\",\n",
    "              \"--\",\"'\",\"''\",\"c\",\"a\",\n",
    "              \"b\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\n",
    "              \"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluates Similarity between sentences using WordNet path similarity\n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    # Tokenize\n",
    "    sent1 = ' '.join([x.lower() for x in wt(sentence1) if x.lower() not in stop_words])\n",
    "    sent2 = ' '.join([x.lower() for x in wt(sentence2) if x.lower() not in stop_words])\n",
    "    \n",
    "    synsets1 = nlp(sent1)\n",
    "    synsets2 = nlp(sent2)\n",
    "\n",
    "    score, count = 0.0, 0\n",
    "\n",
    "    for synset in synsets1:\n",
    "        try:\n",
    "            # print(synset)\n",
    "            best_score = []\n",
    "            for ss in synsets2:\n",
    "                best_score.append(synset.similarity(ss))\n",
    "            # print(best_score)\n",
    "            best_score.append(0)\n",
    "            best_score = max(x for x in best_score if x is not None)\n",
    "            # best_score = max([synset.path_similarity(ss) for ss in synsets2])\n",
    "        except:\n",
    "            print(\"Error: Couldn't do scoring\")\n",
    "            best_score = None\n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score = score + best_score\n",
    "        count = count + 1\n",
    "    if count != 0:\n",
    "        score = score / count\n",
    "        return score\n",
    "    else:\n",
    "        # print(\"Error: Can't divide by count = 0\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Two way similarity measure: Main function, call this to evaluate similarity\n",
    "def symmetric_sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the symmetric sentence similarity using Wordnet \"\"\"\n",
    "    return (sentence_similarity(sentence1, sentence2) + sentence_similarity(sentence2, sentence1))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing technique with LnT data\n",
    "\n",
    "## Import Business Model Characteristics\n",
    "chars = pd.read_csv(characteristics, encoding='latin1')\n",
    "\n",
    "## Import LnT Annual Report paragraphs\n",
    "lnt = pd.read_excel(company,  encoding='latin1')\n",
    "\n",
    "\n",
    "# Begin Timer\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "## Parse paragraphs into individual sentences\n",
    "lnt_sent = []\n",
    "\n",
    "for i in range(len(lnt)):\n",
    "    lnt_sent.append(st(str(lnt.iloc[i, 0])))\n",
    "\n",
    "full_lnt = [sent for sublist in lnt_sent for sent in sublist]\n",
    "\n",
    "df_lnt = pd.DataFrame({'Text': full_lnt})\n",
    "\n",
    "\n",
    "# Evaluate similarity of sentences with individual characteristics\n",
    "\n",
    "for i in range(len(chars)):\n",
    "    characteristics = []\n",
    "    n=100\n",
    "\n",
    "    for row in full_lnt:\n",
    "        s1_d1=row[0:n]\n",
    "        s1_d2=row[n:2*n]\n",
    "        s1_d3=row[2*n:3*n]\n",
    "        \n",
    "        s2_d1=chars.iloc[i,0][0:n]\n",
    "        s2_d2=chars.iloc[i,0][n:2*n]\n",
    "        s2_d3=chars.iloc[i,0][2*n:3*n]\n",
    "        characteristics.append(euclidean_similarity(str(s1_d1), str(s2_d1)))\n",
    "        characteristics.append(euclidean_similarity(str(s1_d2), str(s2_d2)))\n",
    "        characteristics.append(euclidean_similarity(str(s1_d3), str(s2_d3)))\n",
    "    df_lnt[i] = characteristics\n",
    "    print(i)\n",
    "\n",
    "#Export results into an Excel file\n",
    "df_lnt.to_excel(export_path)\n",
    "\n",
    "# Time Elapsed\n",
    "print(\"\\nTime elapsed: {:.2f}s\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
